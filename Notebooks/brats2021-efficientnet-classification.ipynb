{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":29653,"databundleVersionId":2420395,"sourceType":"competition"}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install monai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:05:17.093850Z","iopub.execute_input":"2025-02-16T05:05:17.094108Z","iopub.status.idle":"2025-02-16T05:05:22.521058Z","shell.execute_reply.started":"2025-02-16T05:05:17.094083Z","shell.execute_reply":"2025-02-16T05:05:22.519901Z"}},"outputs":[{"name":"stdout","text":"Collecting monai\n  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.10/dist-packages (from monai) (1.26.4)\nRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.5.1+cu121)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.24->monai) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.24->monai) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.24->monai) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.24->monai) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.24->monai) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.24->monai) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0,>=1.24->monai) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.24->monai) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0,>=1.24->monai) (2024.2.0)\nDownloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: monai\nSuccessfully installed monai-1.4.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport pydicom\nfrom torch.utils.data import Dataset, DataLoader\n\n# Transformations\nfrom scipy.ndimage import zoom \nfrom monai.transforms import (\n   Compose,\n   ScaleIntensityd,\n   NormalizeIntensityd,\n   ScaleIntensityRanged,\n   RandFlipd,\n   RandRotate90d,\n   RandShiftIntensityd\n)\n\n# Model\nfrom monai.networks.nets import DenseNet121, DenseNet169, EfficientNetBN\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:17:25.876168Z","iopub.execute_input":"2025-02-16T05:17:25.876522Z","iopub.status.idle":"2025-02-16T05:17:25.882591Z","shell.execute_reply.started":"2025-02-16T05:17:25.876497Z","shell.execute_reply":"2025-02-16T05:17:25.881563Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"source_dir = '/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/train'\nannotations_file = '/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:10:45.405236Z","iopub.execute_input":"2025-02-16T05:10:45.405458Z","iopub.status.idle":"2025-02-16T05:10:45.408918Z","shell.execute_reply.started":"2025-02-16T05:10:45.405440Z","shell.execute_reply":"2025-02-16T05:10:45.408017Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"annotations_df = pd.read_csv(annotations_file,\n                            dtype = {\"BraTS21ID\": str})\nannotations_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:10:49.198485Z","iopub.execute_input":"2025-02-16T05:10:49.198824Z","iopub.status.idle":"2025-02-16T05:10:49.234212Z","shell.execute_reply.started":"2025-02-16T05:10:49.198795Z","shell.execute_reply":"2025-02-16T05:10:49.233450Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"  BraTS21ID  MGMT_value\n0     00000           1\n1     00002           1\n2     00003           0\n3     00005           1\n4     00006           1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BraTS21ID</th>\n      <th>MGMT_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00002</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00003</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00005</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00006</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## Define the problematic cases","metadata":{}},{"cell_type":"code","source":"problematic_cases = ['00109', '00123', '00709']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:10:53.326710Z","iopub.execute_input":"2025-02-16T05:10:53.327035Z","iopub.status.idle":"2025-02-16T05:10:53.330665Z","shell.execute_reply.started":"2025-02-16T05:10:53.327011Z","shell.execute_reply":"2025-02-16T05:10:53.329772Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Split Data by Patient Cases","metadata":{}},{"cell_type":"code","source":"def get_slice_paths(patient_modality_path):\n    all_slices = []\n    for slice_img in os.listdir(patient_modality_path):\n        if slice_img.endswith('.dcm'):\n            all_slices.append(os.path.join(patient_modality_path, slice_img))\n    return sorted(all_slices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:10:58.682286Z","iopub.execute_input":"2025-02-16T05:10:58.682575Z","iopub.status.idle":"2025-02-16T05:10:58.687219Z","shell.execute_reply.started":"2025-02-16T05:10:58.682554Z","shell.execute_reply":"2025-02-16T05:10:58.686248Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def split_data(source_dir, problematic_cases, train_size, test_size, val_size, modality):\n        # Get all patient cases\n    patient_cases = [ patient_id for patient_id in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, patient_id)) ]\n    \n    # Filter out the problematic cases\n    patient_cases = [case for case in patient_cases if case not in problematic_cases ]\n    \n    train_val_cases, test_cases = train_test_split(\n        patient_cases,\n        test_size = test_size,\n        random_state = 42\n    )\n    \n    val_size_adjusted = val_size/(train_size + val_size)\n    \n    train_cases, val_cases = train_test_split(\n        train_val_cases,\n        test_size = val_size_adjusted,\n        random_state =42    )\n    return {\n        'train':{\n            'patient_ids': train_cases,\n            'paths': {patient_id: os.path.join(source_dir, patient_id) for patient_id in train_cases},\n            'slices': {patient_id: get_slice_paths(os.path.join(source_dir, patient_id, modality)) for patient_id in train_cases}\n        },\n        'val':{\n            'patient_ids': val_cases,\n            'paths': {patient_id: os.path.join(source_dir, patient_id) for patient_id in val_cases},\n            'slices': {patient_id: get_slice_paths(os.path.join(source_dir, patient_id, modality)) for patient_id in val_cases}     \n        \n        },\n        'test':{\n            'patient_ids': test_cases,\n            'paths': {patient_id: os.path.join(source_dir, patient_id) for patient_id in test_cases},\n            'slices': {patient_id: get_slice_paths(os.path.join(source_dir, patient_id, modality)) for patient_id in test_cases}     \n        \n        }\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:10:58.688339Z","iopub.execute_input":"2025-02-16T05:10:58.688634Z","iopub.status.idle":"2025-02-16T05:10:58.709367Z","shell.execute_reply.started":"2025-02-16T05:10:58.688605Z","shell.execute_reply":"2025-02-16T05:10:58.708657Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Split data\nsplits = split_data(\n    source_dir=source_dir,\n    train_size=0.7,\n    test_size=0.15,\n    val_size=0.15,\n    problematic_cases = problematic_cases,\n    modality = 'FLAIR')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:10:58.710536Z","iopub.execute_input":"2025-02-16T05:10:58.710795Z","iopub.status.idle":"2025-02-16T05:11:12.097231Z","shell.execute_reply.started":"2025-02-16T05:10:58.710775Z","shell.execute_reply":"2025-02-16T05:11:12.096404Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# splits['train']['slices']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:11:12.098434Z","iopub.execute_input":"2025-02-16T05:11:12.098675Z","iopub.status.idle":"2025-02-16T05:11:12.103002Z","shell.execute_reply.started":"2025-02-16T05:11:12.098656Z","shell.execute_reply":"2025-02-16T05:11:12.101375Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Define the Custom BraTs Dataset","metadata":{}},{"cell_type":"code","source":"class BraTsDataset(Dataset):\n\n    def __init__(self, data_dict, annotations_df, transforms = None, cache_size = 0):\n        self.patient_ids = data_dict['patient_ids']\n        self.slice_paths = data_dict['slices']\n        self.transforms = transforms\n\n        self.cache_size = cache_size\n        self.cache = {}\n        self.labels = dict(zip(annotations_df['BraTS21ID'], annotations_df['MGMT_value'])) \n\n    def __len__(self):\n        return len(self.patient_ids)\n\n    def load_volume(self, patient_id):\n        if patient_id in self.cache:\n            return self.cache[patient_id]\n        slices = []\n        for slice_path in self.slice_paths[patient_id]:\n            dicom_image = pydicom.dcmread(slice_path)\n            image_2d = dicom_image.pixel_array\n            resized_slice = zoom(image_2d, (64/image_2d.shape[0], 64/image_2d.shape[1]))\n            slices.append(resized_slice)\n           \n        volume = np.stack(slices, axis=-1)\n        volume = np.expand_dims(volume, axis=0)\n        volume_tensor = torch.from_numpy(volume).float()\n\n        # Print range before normalization\n        # print(f\"Before normalization: [{volume_tensor.min():.3f}, {volume_tensor.max():.3f}]\")\n\n        # Add normalization here\n        volume_tensor = (volume_tensor - volume_tensor.min()) / (volume_tensor.max() - volume_tensor.min())\n       \n        # Print range after normalization\n        # print(f\"After normalization: [{volume_tensor.min():.3f}, {volume_tensor.max():.3f}]\")\n       \n        \n        if len(self.cache) < self.cache_size:\n            self.cache[patient_id] = volume_tensor\n           \n        return volume_tensor\n\n    \n    def __getitem__(self, idx):\n        \n        patient_id = self.patient_ids[idx]\n        volume = self.load_volume(patient_id)\n        label = torch.tensor(self.labels[patient_id])\n        \n        data = {\"image\": volume, \n                \"patient_id\": patient_id,\n                \"label\": label\n               }\n        \n        # Add print statements for debugging\n        # print(f\"Before transform range: [{data['image'].min():.3f}, {data['image'].max():.3f}]\")\n        # print(\"Data keys:\", data.keys())\n        \n        # if self.transforms:\n        #     data = self.transforms(data)\n            \n        # print(f\"After transform range: [{data['image'].min():.3f}, {data['image'].max():.3f}]\")\n            \n        \n        return data\n        \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:11:12.103893Z","iopub.execute_input":"2025-02-16T05:11:12.104181Z","iopub.status.idle":"2025-02-16T05:11:12.146533Z","shell.execute_reply.started":"2025-02-16T05:11:12.104156Z","shell.execute_reply":"2025-02-16T05:11:12.145606Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_split = splits['train']\nval_split = splits['val']\ntest_split = splits['test']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:11:12.147489Z","iopub.execute_input":"2025-02-16T05:11:12.147831Z","iopub.status.idle":"2025-02-16T05:11:12.165746Z","shell.execute_reply.started":"2025-02-16T05:11:12.147798Z","shell.execute_reply":"2025-02-16T05:11:12.164919Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Check split data structure\nprint(\"Train split keys:\", train_split.keys())\nprint(\"First few patient IDs:\", train_split['patient_ids'][:3])\n\n# Check if paths are correct\nfirst_patient = train_split['patient_ids'][0]\nprint(\"First patient paths:\", train_split['slices'][first_patient][:3])\n\n# Create dataset and check\ntrain_dataset = BraTsDataset(train_split, annotations_df)\nsample = train_dataset[0]\nprint(f\"Sample shape: {sample['image'].shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:11:12.166629Z","iopub.execute_input":"2025-02-16T05:11:12.166917Z","iopub.status.idle":"2025-02-16T05:11:12.873713Z","shell.execute_reply.started":"2025-02-16T05:11:12.166895Z","shell.execute_reply":"2025-02-16T05:11:12.872923Z"}},"outputs":[{"name":"stdout","text":"Train split keys: dict_keys(['patient_ids', 'paths', 'slices'])\nFirst few patient IDs: ['00316', '01007', '00003']\nFirst patient paths: ['/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/train/00316/FLAIR/Image-1.dcm', '/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/train/00316/FLAIR/Image-10.dcm', '/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/train/00316/FLAIR/Image-11.dcm']\nSample shape: torch.Size([1, 64, 64, 60])\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## Define the Transformations","metadata":{}},{"cell_type":"code","source":"train_transforms = Compose([\nScaleIntensityRanged(\n        keys=[\"image\"],\n        a_min=-76,\n        a_max=3158,\n        b_min=0.0,\n        b_max=1.0,\n        clip=True\n    ),    \n    RandFlipd(keys=[\"image\"], spatial_axis=[0, 1], prob=0.5),\n    RandRotate90d(keys=[\"image\"], prob=0.5, spatial_axes=[0, 1]),\n    RandShiftIntensityd(keys=[\"image\"], prob=0.5, offsets=0.1),\n])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:11:12.875930Z","iopub.execute_input":"2025-02-16T05:11:12.876199Z","iopub.status.idle":"2025-02-16T05:11:12.883729Z","shell.execute_reply.started":"2025-02-16T05:11:12.876178Z","shell.execute_reply":"2025-02-16T05:11:12.882954Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Add print to verify transform is in chain\nprint(\"Transforms:\", train_transforms.transforms)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:11:12.885056Z","iopub.execute_input":"2025-02-16T05:11:12.885296Z","iopub.status.idle":"2025-02-16T05:11:12.899065Z","shell.execute_reply.started":"2025-02-16T05:11:12.885267Z","shell.execute_reply":"2025-02-16T05:11:12.898387Z"}},"outputs":[{"name":"stdout","text":"Transforms: (<monai.transforms.intensity.dictionary.ScaleIntensityRanged object at 0x7ee9b1a66260>, <monai.transforms.spatial.dictionary.RandFlipd object at 0x7ee9b1a67700>, <monai.transforms.spatial.dictionary.RandRotate90d object at 0x7ee9b1a674f0>, <monai.transforms.intensity.dictionary.RandShiftIntensityd object at 0x7ee9b1a65c60>)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"val_transforms = Compose([\n   ScaleIntensityd(\n       keys=[\"image\"],\n       minv=0.0,\n       maxv=1.0,\n   ),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:11:12.899787Z","iopub.execute_input":"2025-02-16T05:11:12.900057Z","iopub.status.idle":"2025-02-16T05:11:12.914177Z","shell.execute_reply.started":"2025-02-16T05:11:12.900035Z","shell.execute_reply":"2025-02-16T05:11:12.913407Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Create test transforms and loader\ntest_transforms = Compose([\n   ScaleIntensityd(\n       keys=[\"image\"],\n       minv=0.0,\n       maxv=1.0,\n   ),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:11:12.914888Z","iopub.execute_input":"2025-02-16T05:11:12.915107Z","iopub.status.idle":"2025-02-16T05:11:12.930763Z","shell.execute_reply.started":"2025-02-16T05:11:12.915089Z","shell.execute_reply":"2025-02-16T05:11:12.929917Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"train_dataset = BraTsDataset(train_split, annotations_df, transforms=train_transforms)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:11:12.931607Z","iopub.execute_input":"2025-02-16T05:11:12.931910Z","iopub.status.idle":"2025-02-16T05:11:12.946605Z","shell.execute_reply.started":"2025-02-16T05:11:12.931882Z","shell.execute_reply":"2025-02-16T05:11:12.945998Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"train_dataset = BraTsDataset(train_split, annotations_df)\nval_dataset = BraTsDataset(val_split, annotations_df)\ntest_dataset = BraTsDataset(test_split, annotations_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:11:12.947141Z","iopub.execute_input":"2025-02-16T05:11:12.947322Z","iopub.status.idle":"2025-02-16T05:11:12.961362Z","shell.execute_reply.started":"2025-02-16T05:11:12.947307Z","shell.execute_reply":"2025-02-16T05:11:12.960656Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Check split data structure\nprint(\"Train split keys:\", train_split.keys())\nprint(\"First few patient IDs:\", train_split['patient_ids'][:3])\n\n# Check if paths are correct\nfirst_patient = train_split['patient_ids'][0]\nprint(\"First patient paths:\", train_split['slices'][first_patient][:3])\n\n# Create dataset and check\ntrain_dataset = BraTsDataset(train_split, annotations_df)\nsample= train_dataset[0]\nprint(f\"Train Sample shape: {sample['image'].shape}\")\nprint()\n\nval_dataset = BraTsDataset(val_split, annotations_df)\nsample= val_dataset[0]\nprint(f\"Validation Sample shape: {sample['image'].shape}\")\nprint()\ntest_dataset = BraTsDataset(val_split, annotations_df)\nsample= test_dataset[0]\nprint(f\"Test Sample shape: {sample['image'].shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:11:12.962191Z","iopub.execute_input":"2025-02-16T05:11:12.962450Z","iopub.status.idle":"2025-02-16T05:11:16.949410Z","shell.execute_reply.started":"2025-02-16T05:11:12.962423Z","shell.execute_reply":"2025-02-16T05:11:16.948570Z"}},"outputs":[{"name":"stdout","text":"Train split keys: dict_keys(['patient_ids', 'paths', 'slices'])\nFirst few patient IDs: ['00316', '01007', '00003']\nFirst patient paths: ['/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/train/00316/FLAIR/Image-1.dcm', '/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/train/00316/FLAIR/Image-10.dcm', '/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/train/00316/FLAIR/Image-11.dcm']\nTrain Sample shape: torch.Size([1, 64, 64, 60])\n\nValidation Sample shape: torch.Size([1, 64, 64, 129])\n\nTest Sample shape: torch.Size([1, 64, 64, 129])\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## Define the DataLoader","metadata":{}},{"cell_type":"code","source":"# def custom_collate(batch):\n    \n#     min_val = min([item[\"image\"].min().item() for item in batch])\n#     max_val = max([item[\"image\"].max().item() for item in batch])\n\n#     # print(f\"Collate input range: [{min_val:.3f}, {max_val:.3f}]\")\n    \n#     max_depth = max([x[\"image\"].shape[-1] for x in batch])  # x[0] is volume\n#     padded_batch = []\n#     labels = []\n#     for data in batch:\n#         volume = data[\"image\"]\n#         label = data[\"label\"]\n#         pad_size = max_depth - volume.shape[-1]\n        \n#         if pad_size > 0:\n#             padded_volume = torch.nn.functional.pad(volume, (0, pad_size))\n#             padded_batch.append(padded_volume)\n        \n#         else:\n#             padded_batch.append(volume)\n#         labels.append(label)\n    \n#     return { \n#         \"image\": torch.stack(padded_batch), \n#         \"label\": torch.tensor(labels)\n#            }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:11:16.950341Z","iopub.execute_input":"2025-02-16T05:11:16.950673Z","iopub.status.idle":"2025-02-16T05:11:16.954341Z","shell.execute_reply.started":"2025-02-16T05:11:16.950639Z","shell.execute_reply":"2025-02-16T05:11:16.953441Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def custom_collate(batch):\n    max_depth = 32  # Fixed depth\n    padded_batch = []\n    labels = []\n    \n    for data in batch:\n        volume = data['image']\n        label = data['label']\n        \n        current_depth = volume.shape[-1]\n        if current_depth < max_depth:\n            pad_size = max_depth - current_depth\n            padded_volume = torch.nn.functional.pad(volume, (0, pad_size))\n        else:\n            padded_volume = volume[..., :max_depth]\n            \n        padded_batch.append(padded_volume)\n        labels.append(label)\n    \n    return {\n        \"image\": torch.stack(padded_batch),\n        \"label\": torch.stack(labels)\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:18:44.957149Z","iopub.execute_input":"2025-02-16T05:18:44.957487Z","iopub.status.idle":"2025-02-16T05:18:44.962897Z","shell.execute_reply.started":"2025-02-16T05:18:44.957460Z","shell.execute_reply":"2025-02-16T05:18:44.961996Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# Create DataLoader\ntrain_loader = DataLoader(\n   train_dataset,\n   batch_size=4,  # Small batch size for 3D data\n   shuffle=True,\n   num_workers=2,\n   collate_fn=custom_collate,\n   pin_memory=True  # Faster data transfer to GPU\n)\n\n\nval_loader = DataLoader(\n   val_dataset,\n   batch_size=4,  # Small batch size for 3D data\n   shuffle=True,\n   num_workers=2,\n   collate_fn=custom_collate,\n   pin_memory=True  # Faster data transfer to GPU\n)\n\n# Create DataLoader\ntest_loader = DataLoader(\n   test_dataset,\n   batch_size=4,  # Small batch size for 3D data\n   shuffle=False,\n   num_workers=2,\n   collate_fn=custom_collate,\n   pin_memory=True  # Faster data transfer to GPU\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:18:44.964278Z","iopub.execute_input":"2025-02-16T05:18:44.964586Z","iopub.status.idle":"2025-02-16T05:18:44.980514Z","shell.execute_reply.started":"2025-02-16T05:18:44.964557Z","shell.execute_reply":"2025-02-16T05:18:44.979792Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"def inspect_batch(dataloader, split_name=\"Unknown\"):\n    \"\"\"Inspects a batch from a given dataloader, printing shape and value range.\"\"\"\n    batch = next(iter(dataloader))  # Get a single batch\n    \n    images, labels = batch[\"image\"], batch[\"label\"]\n    \n    min_val, max_val = images.min().item(), images.max().item()\n    \n    print(f\"\\n--- {split_name} Split Batch Inspection ---\")\n    print(f\"Image Batch Shape: {images.shape}\")  # Expected: (batch_size, channels, height, width, depth)\n    print(f\"Label Batch Shape: {labels.shape}\")  # Should match batch_size\n    print(f\"Value Range: [{min_val:.3f}, {max_val:.3f}]\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:18:44.981790Z","iopub.execute_input":"2025-02-16T05:18:44.982066Z","iopub.status.idle":"2025-02-16T05:18:44.994804Z","shell.execute_reply.started":"2025-02-16T05:18:44.982047Z","shell.execute_reply":"2025-02-16T05:18:44.994162Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# inspect_batch(train_loader, \"Train\")\n# inspect_batch(val_loader, \"Validation\")\n# inspect_batch(test_loader, \"Test\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:18:44.995801Z","iopub.execute_input":"2025-02-16T05:18:44.996087Z","iopub.status.idle":"2025-02-16T05:18:45.008341Z","shell.execute_reply.started":"2025-02-16T05:18:44.996053Z","shell.execute_reply":"2025-02-16T05:18:45.007468Z"}},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":"# Define the model","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:18:45.009194Z","iopub.execute_input":"2025-02-16T05:18:45.009446Z","iopub.status.idle":"2025-02-16T05:18:45.028157Z","shell.execute_reply.started":"2025-02-16T05:18:45.009426Z","shell.execute_reply":"2025-02-16T05:18:45.027371Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# model = DenseNet121(\n#     spatial_dims = 3,\n#     in_channels = 1,\n#     out_channels = 1\n# ).to(device)\n\n# model = DenseNet169(\n#     spatial_dims = 3,\n#     in_channels = 1,\n#     out_channels = 1\n# ).to(device)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T05:18:45.028937Z","iopub.execute_input":"2025-02-16T05:18:45.029236Z","iopub.status.idle":"2025-02-16T05:18:45.042874Z","shell.execute_reply.started":"2025-02-16T05:18:45.029203Z","shell.execute_reply":"2025-02-16T05:18:45.042110Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# EfficientNet-B1\nmodel = EfficientNetBN(\n    model_name=\"efficientnet-b1\",\n    spatial_dims=3,\n    in_channels=1,\n    num_classes=1\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T08:18:38.848025Z","iopub.execute_input":"2025-02-16T08:18:38.848389Z","iopub.status.idle":"2025-02-16T08:18:39.038448Z","shell.execute_reply.started":"2025-02-16T08:18:38.848366Z","shell.execute_reply":"2025-02-16T08:18:39.037738Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = Adam(model.parameters(), lr = 1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T08:18:42.774188Z","iopub.execute_input":"2025-02-16T08:18:42.774478Z","iopub.status.idle":"2025-02-16T08:18:42.782480Z","shell.execute_reply.started":"2025-02-16T08:18:42.774457Z","shell.execute_reply":"2025-02-16T08:18:42.781839Z"}},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":"## Set up the Training Loop","metadata":{}},{"cell_type":"code","source":"def train_epoch(model, train_loader, val_loader, epochs = 50):\n    best_val_acc = 0.0\n    for epoch in range(epochs):\n        \n        model.train()  # setting the model in train mode\n        train_loss = 0.0 # initialize variable to store the sum of loss\n        \n        for batch in tqdm(train_loader, desc = f'Epoch {epoch+1}/{epochs} - Training'):\n            # Pass through the training set for the no. of epochs\n            images = batch['image'].to(device)\n            labels = batch['label'].float().to(device)\n\n        \n            optimizer.zero_grad()\n            outputs = model(images)\n        \n            loss = criterion(outputs.squeeze(), labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            \n        # Calculatie average loss for epoch\n        avg_train_loss = train_loss/len(train_loader)\n        \n        # Validation Phase\n        model.eval()\n        val_loss = 0.0\n        correct = 0\n        total = 0\n\n        with torch.no_grad(): # No gradient calculation needed\n            for batch in tqdm(val_loader, desc = f'Epoch {epoch + 1}/{epochs} - Validation'):\n                images = batch['image'].to(device)\n                labels = batch['label'].float().to(device)\n                \n                outputs = model(images)\n                \n                val_loss += criterion(outputs.squeeze(), labels).item()\n\n                predicted = (torch.sigmoid(outputs.squeeze()) > 0.5).int()\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n                \n        val_accuracy = 100*correct/total\n        avg_val_loss = val_loss/len(val_loader)\n        \n        if val_accuracy > best_val_acc:\n            best_val_acc = val_accuracy\n            torch.save(model.state_dict(), '/kaggle/working/best_model.pth')\n        \n        # Print epoch results\n        print(f'Epoch [{epoch+1}/{epochs}]')\n        print(f'Training Loss: {avg_train_loss:.4f}')\n        print(f'Validation Loss: {avg_val_loss:.4f}')\n        print(f'Validation Accuracy: {val_accuracy:.2f}%')\n        print('-' * 50)\n\n\n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T08:18:45.531371Z","iopub.execute_input":"2025-02-16T08:18:45.531670Z","iopub.status.idle":"2025-02-16T08:18:45.539662Z","shell.execute_reply.started":"2025-02-16T08:18:45.531645Z","shell.execute_reply":"2025-02-16T08:18:45.538748Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"# Run training for 50 epochs\nnum_epochs = 30\ntrain_epoch(model, train_loader, val_loader, epochs=num_epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T08:18:49.955551Z","iopub.execute_input":"2025-02-16T08:18:49.955844Z","iopub.status.idle":"2025-02-16T10:31:40.666581Z","shell.execute_reply.started":"2025-02-16T08:18:49.955822Z","shell.execute_reply":"2025-02-16T10:31:40.665411Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/30 - Training: 100%|██████████| 102/102 [03:45<00:00,  2.21s/it]\nEpoch 1/30 - Validation: 100%|██████████| 22/22 [00:54<00:00,  2.47s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/30]\nTraining Loss: 3.4046\nValidation Loss: 0.8617\nValidation Accuracy: 54.55%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/30 - Training: 100%|██████████| 102/102 [03:13<00:00,  1.90s/it]\nEpoch 2/30 - Validation: 100%|██████████| 22/22 [00:49<00:00,  2.23s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/30]\nTraining Loss: 2.2133\nValidation Loss: 0.9245\nValidation Accuracy: 54.55%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/30 - Training: 100%|██████████| 102/102 [03:22<00:00,  1.98s/it]\nEpoch 3/30 - Validation: 100%|██████████| 22/22 [01:00<00:00,  2.76s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/30]\nTraining Loss: 2.5898\nValidation Loss: 0.8339\nValidation Accuracy: 54.55%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/30 - Training: 100%|██████████| 102/102 [03:27<00:00,  2.04s/it]\nEpoch 4/30 - Validation: 100%|██████████| 22/22 [00:50<00:00,  2.29s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/30]\nTraining Loss: 2.0604\nValidation Loss: 0.9808\nValidation Accuracy: 54.55%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/30 - Training: 100%|██████████| 102/102 [03:15<00:00,  1.92s/it]\nEpoch 5/30 - Validation: 100%|██████████| 22/22 [00:55<00:00,  2.54s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/30]\nTraining Loss: 2.1129\nValidation Loss: 0.6989\nValidation Accuracy: 54.55%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/30 - Training: 100%|██████████| 102/102 [03:31<00:00,  2.07s/it]\nEpoch 6/30 - Validation: 100%|██████████| 22/22 [00:51<00:00,  2.33s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/30]\nTraining Loss: 1.9821\nValidation Loss: 0.8907\nValidation Accuracy: 54.55%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/30 - Training: 100%|██████████| 102/102 [03:24<00:00,  2.01s/it]\nEpoch 7/30 - Validation: 100%|██████████| 22/22 [00:52<00:00,  2.40s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/30]\nTraining Loss: 1.6337\nValidation Loss: 0.7301\nValidation Accuracy: 45.45%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/30 - Training: 100%|██████████| 102/102 [03:42<00:00,  2.18s/it]\nEpoch 8/30 - Validation: 100%|██████████| 22/22 [00:53<00:00,  2.44s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/30]\nTraining Loss: 1.7950\nValidation Loss: 0.6969\nValidation Accuracy: 55.68%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/30 - Training: 100%|██████████| 102/102 [03:28<00:00,  2.05s/it]\nEpoch 9/30 - Validation: 100%|██████████| 22/22 [00:47<00:00,  2.17s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/30]\nTraining Loss: 1.1090\nValidation Loss: 0.7141\nValidation Accuracy: 53.41%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/30 - Training: 100%|██████████| 102/102 [03:46<00:00,  2.22s/it]\nEpoch 10/30 - Validation: 100%|██████████| 22/22 [00:49<00:00,  2.27s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/30]\nTraining Loss: 1.5572\nValidation Loss: 0.8283\nValidation Accuracy: 54.55%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/30 - Training: 100%|██████████| 102/102 [03:25<00:00,  2.02s/it]\nEpoch 11/30 - Validation: 100%|██████████| 22/22 [00:49<00:00,  2.23s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [11/30]\nTraining Loss: 1.0319\nValidation Loss: 2.9543\nValidation Accuracy: 44.32%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/30 - Training: 100%|██████████| 102/102 [03:30<00:00,  2.06s/it]\nEpoch 12/30 - Validation: 100%|██████████| 22/22 [01:03<00:00,  2.89s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [12/30]\nTraining Loss: 1.0120\nValidation Loss: 2.1087\nValidation Accuracy: 55.68%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/30 - Training: 100%|██████████| 102/102 [03:42<00:00,  2.18s/it]\nEpoch 13/30 - Validation: 100%|██████████| 22/22 [00:52<00:00,  2.39s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [13/30]\nTraining Loss: 1.1381\nValidation Loss: 3.8838\nValidation Accuracy: 48.86%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/30 - Training: 100%|██████████| 102/102 [03:31<00:00,  2.08s/it]\nEpoch 14/30 - Validation: 100%|██████████| 22/22 [00:55<00:00,  2.54s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [14/30]\nTraining Loss: 1.0956\nValidation Loss: 1.0064\nValidation Accuracy: 61.36%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/30 - Training: 100%|██████████| 102/102 [03:23<00:00,  1.99s/it]\nEpoch 15/30 - Validation: 100%|██████████| 22/22 [00:47<00:00,  2.17s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [15/30]\nTraining Loss: 0.7975\nValidation Loss: 0.9574\nValidation Accuracy: 60.23%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/30 - Training: 100%|██████████| 102/102 [03:36<00:00,  2.12s/it]\nEpoch 16/30 - Validation: 100%|██████████| 22/22 [00:53<00:00,  2.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [16/30]\nTraining Loss: 0.7350\nValidation Loss: 0.8940\nValidation Accuracy: 61.36%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/30 - Training: 100%|██████████| 102/102 [03:26<00:00,  2.02s/it]\nEpoch 17/30 - Validation: 100%|██████████| 22/22 [00:54<00:00,  2.46s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [17/30]\nTraining Loss: 0.7473\nValidation Loss: 1.4208\nValidation Accuracy: 50.00%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/30 - Training: 100%|██████████| 102/102 [03:46<00:00,  2.22s/it]\nEpoch 18/30 - Validation: 100%|██████████| 22/22 [00:52<00:00,  2.39s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [18/30]\nTraining Loss: 0.7294\nValidation Loss: 4.2420\nValidation Accuracy: 53.41%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/30 - Training: 100%|██████████| 102/102 [03:21<00:00,  1.98s/it]\nEpoch 19/30 - Validation: 100%|██████████| 22/22 [00:53<00:00,  2.45s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [19/30]\nTraining Loss: 0.5482\nValidation Loss: 1.9928\nValidation Accuracy: 52.27%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/30 - Training: 100%|██████████| 102/102 [03:22<00:00,  1.98s/it]\nEpoch 20/30 - Validation: 100%|██████████| 22/22 [00:54<00:00,  2.46s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [20/30]\nTraining Loss: 0.4808\nValidation Loss: 1.2981\nValidation Accuracy: 53.41%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/30 - Training: 100%|██████████| 102/102 [03:24<00:00,  2.01s/it]\nEpoch 21/30 - Validation: 100%|██████████| 22/22 [00:56<00:00,  2.55s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [21/30]\nTraining Loss: 0.4719\nValidation Loss: 2.2453\nValidation Accuracy: 51.14%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/30 - Training: 100%|██████████| 102/102 [03:29<00:00,  2.05s/it]\nEpoch 22/30 - Validation: 100%|██████████| 22/22 [00:52<00:00,  2.39s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [22/30]\nTraining Loss: 0.5147\nValidation Loss: 1.7665\nValidation Accuracy: 56.82%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/30 - Training: 100%|██████████| 102/102 [03:37<00:00,  2.13s/it]\nEpoch 23/30 - Validation: 100%|██████████| 22/22 [00:58<00:00,  2.66s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [23/30]\nTraining Loss: 0.6187\nValidation Loss: 2.1586\nValidation Accuracy: 47.73%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/30 - Training: 100%|██████████| 102/102 [03:45<00:00,  2.21s/it]\nEpoch 24/30 - Validation: 100%|██████████| 22/22 [00:50<00:00,  2.30s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [24/30]\nTraining Loss: 0.5600\nValidation Loss: 1.5631\nValidation Accuracy: 53.41%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/30 - Training: 100%|██████████| 102/102 [03:17<00:00,  1.94s/it]\nEpoch 25/30 - Validation: 100%|██████████| 22/22 [00:53<00:00,  2.41s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [25/30]\nTraining Loss: 0.4359\nValidation Loss: 1.4904\nValidation Accuracy: 42.05%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/30 - Training: 100%|██████████| 102/102 [03:20<00:00,  1.96s/it]\nEpoch 26/30 - Validation: 100%|██████████| 22/22 [01:16<00:00,  3.46s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [26/30]\nTraining Loss: 0.5032\nValidation Loss: 1.4833\nValidation Accuracy: 52.27%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/30 - Training: 100%|██████████| 102/102 [03:37<00:00,  2.13s/it]\nEpoch 27/30 - Validation: 100%|██████████| 22/22 [00:52<00:00,  2.38s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [27/30]\nTraining Loss: 0.2751\nValidation Loss: 1.5049\nValidation Accuracy: 51.14%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/30 - Training: 100%|██████████| 102/102 [03:45<00:00,  2.21s/it]\nEpoch 28/30 - Validation: 100%|██████████| 22/22 [00:59<00:00,  2.69s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [28/30]\nTraining Loss: 0.4440\nValidation Loss: 2.4459\nValidation Accuracy: 47.73%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/30 - Training: 100%|██████████| 102/102 [03:57<00:00,  2.32s/it]\nEpoch 29/30 - Validation: 100%|██████████| 22/22 [00:56<00:00,  2.57s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [29/30]\nTraining Loss: 0.3920\nValidation Loss: 2.1937\nValidation Accuracy: 48.86%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/30 - Training: 100%|██████████| 102/102 [03:20<00:00,  1.97s/it]\nEpoch 30/30 - Validation: 100%|██████████| 22/22 [00:51<00:00,  2.35s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [30/30]\nTraining Loss: 0.3449\nValidation Loss: 1.6413\nValidation Accuracy: 45.45%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"def test_model(model, test_loader, criterion):\n    # Load best model weights\n    model.load_state_dict(torch.load('/kaggle/working/best_model.pth'))\n    model.eval()  # Set to evaluation mode\n    \n    test_loss = 0.0\n    correct = 0\n    total = 0\n    \n    # For storing predictions and true labels\n    all_predictions = []\n    all_labels = []\n    \n    test_pbar = tqdm(test_loader, desc='Testing')\n    with torch.no_grad():\n        for batch in test_pbar:\n            images = batch['image'].to(device)\n            labels = batch['label'].to(device)\n            \n            outputs = model(images)\n            test_loss += criterion(outputs.squeeze(), labels.float()).item()\n            \n            predicted = (torch.sigmoid(outputs.squeeze()) > 0.5).int()\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            # Store predictions and labels\n            all_predictions.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            \n            # Update progress bar\n            current_acc = 100 * correct / total\n            test_pbar.set_postfix({'acc': f'{current_acc:.2f}%'})\n    \n    # Calculate final metrics\n    test_accuracy = 100 * correct / total\n    avg_test_loss = test_loss / len(test_loader)\n    \n    print('\\nTest Results:')\n    print(f'Test Loss: {avg_test_loss:.4f}')\n    print(f'Test Accuracy: {test_accuracy:.2f}%')\n    \n    return test_accuracy, avg_test_loss, all_predictions, all_labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T10:31:52.206148Z","iopub.execute_input":"2025-02-16T10:31:52.206457Z","iopub.status.idle":"2025-02-16T10:31:52.213086Z","shell.execute_reply.started":"2025-02-16T10:31:52.206429Z","shell.execute_reply":"2025-02-16T10:31:52.212151Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# Run testing\ntest_accuracy, test_loss, predictions, true_labels = test_model(model, test_loader, criterion)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T10:31:56.819674Z","iopub.execute_input":"2025-02-16T10:31:56.820026Z","iopub.status.idle":"2025-02-16T10:32:51.916365Z","shell.execute_reply.started":"2025-02-16T10:31:56.819961Z","shell.execute_reply":"2025-02-16T10:32:51.915294Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-51-73c904e42cb2>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('/kaggle/working/best_model.pth'))\nTesting: 100%|██████████| 22/22 [00:54<00:00,  2.50s/it, acc=61.36%]","output_type":"stream"},{"name":"stdout","text":"\nTest Results:\nTest Loss: 1.0064\nTest Accuracy: 61.36%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"print('Test Accuracy: ',test_accuracy)\nprint('Test Loss: ',test_loss)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T07:40:45.662731Z","iopub.execute_input":"2025-02-16T07:40:45.663091Z","iopub.status.idle":"2025-02-16T07:40:45.667369Z","shell.execute_reply.started":"2025-02-16T07:40:45.663065Z","shell.execute_reply":"2025-02-16T07:40:45.666610Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy:  61.36363636363637\nTest Loss:  0.879914247176864\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}