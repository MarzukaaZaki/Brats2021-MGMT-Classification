{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":29653,"databundleVersionId":2420395,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install monai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:15:20.379784Z","iopub.execute_input":"2025-02-06T05:15:20.380063Z","iopub.status.idle":"2025-02-06T05:15:26.022791Z","shell.execute_reply.started":"2025-02-06T05:15:20.380035Z","shell.execute_reply":"2025-02-06T05:15:26.021932Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport pydicom\nfrom torch.utils.data import Dataset, DataLoader\n\n# Transformations\nfrom scipy.ndimage import zoom \nfrom monai.transforms import (\n   Compose,\n   ScaleIntensityd,\n   NormalizeIntensityd,\n   ScaleIntensityRanged,\n   RandFlipd,\n   RandRotate90d,\n   RandShiftIntensityd\n)\n\n# Model\nfrom monai.networks.nets import DenseNet121, DenseNet169\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:15:26.023730Z","iopub.execute_input":"2025-02-06T05:15:26.024026Z","iopub.status.idle":"2025-02-06T05:15:50.734906Z","shell.execute_reply.started":"2025-02-06T05:15:26.023988Z","shell.execute_reply":"2025-02-06T05:15:50.734248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"source_dir = '/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/train'\nannotations_file = '/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:15:50.735821Z","iopub.execute_input":"2025-02-06T05:15:50.736593Z","iopub.status.idle":"2025-02-06T05:15:50.740055Z","shell.execute_reply.started":"2025-02-06T05:15:50.736560Z","shell.execute_reply":"2025-02-06T05:15:50.739247Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"annotations_df = pd.read_csv(annotations_file,\n                            dtype = {\"BraTS21ID\": str})\nannotations_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:15:50.742263Z","iopub.execute_input":"2025-02-06T05:15:50.742541Z","iopub.status.idle":"2025-02-06T05:15:50.811629Z","shell.execute_reply.started":"2025-02-06T05:15:50.742513Z","shell.execute_reply":"2025-02-06T05:15:50.810992Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define the problematic cases","metadata":{}},{"cell_type":"code","source":"problematic_cases = ['00109', '00123', '00709']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:15:50.812950Z","iopub.execute_input":"2025-02-06T05:15:50.813235Z","iopub.status.idle":"2025-02-06T05:15:50.816349Z","shell.execute_reply.started":"2025-02-06T05:15:50.813214Z","shell.execute_reply":"2025-02-06T05:15:50.815719Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Split Data by Patient Cases","metadata":{}},{"cell_type":"code","source":"def get_slice_paths(patient_modality_path):\n    all_slices = []\n    for slice_img in os.listdir(patient_modality_path):\n        if slice_img.endswith('.dcm'):\n            all_slices.append(os.path.join(patient_modality_path, slice_img))\n    return sorted(all_slices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:15:50.817147Z","iopub.execute_input":"2025-02-06T05:15:50.817423Z","iopub.status.idle":"2025-02-06T05:15:50.833370Z","shell.execute_reply.started":"2025-02-06T05:15:50.817373Z","shell.execute_reply":"2025-02-06T05:15:50.832664Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def split_data(source_dir, problematic_cases, train_size, test_size, val_size, modality):\n        # Get all patient cases\n    patient_cases = [ patient_id for patient_id in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, patient_id)) ]\n    \n    # Filter out the problematic cases\n    patient_cases = [case for case in patient_cases if case not in problematic_cases ]\n    \n    train_val_cases, test_cases = train_test_split(\n        patient_cases,\n        test_size = test_size,\n        random_state = 42\n    )\n    \n    val_size_adjusted = val_size/(train_size + val_size)\n    \n    train_cases, val_cases = train_test_split(\n        train_val_cases,\n        test_size = val_size_adjusted,\n        random_state =42    )\n    return {\n        'train':{\n            'patient_ids': train_cases,\n            'paths': {patient_id: os.path.join(source_dir, patient_id) for patient_id in train_cases},\n            'slices': {patient_id: get_slice_paths(os.path.join(source_dir, patient_id, modality)) for patient_id in train_cases}\n        },\n        'val':{\n            'patient_ids': val_cases,\n            'paths': {patient_id: os.path.join(source_dir, patient_id) for patient_id in val_cases},\n            'slices': {patient_id: get_slice_paths(os.path.join(source_dir, patient_id, modality)) for patient_id in val_cases}     \n        \n        },\n        'test':{\n            'patient_ids': test_cases,\n            'paths': {patient_id: os.path.join(source_dir, patient_id) for patient_id in test_cases},\n            'slices': {patient_id: get_slice_paths(os.path.join(source_dir, patient_id, modality)) for patient_id in test_cases}     \n        \n        }\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:15:50.834055Z","iopub.execute_input":"2025-02-06T05:15:50.834296Z","iopub.status.idle":"2025-02-06T05:15:50.843954Z","shell.execute_reply.started":"2025-02-06T05:15:50.834277Z","shell.execute_reply":"2025-02-06T05:15:50.843275Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split data\nsplits = split_data(\n    source_dir=source_dir,\n    train_size=0.7,\n    test_size=0.15,\n    val_size=0.15,\n    problematic_cases = problematic_cases,\n    modality = 'FLAIR')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:15:50.844677Z","iopub.execute_input":"2025-02-06T05:15:50.844948Z","iopub.status.idle":"2025-02-06T05:16:04.994079Z","shell.execute_reply.started":"2025-02-06T05:15:50.844923Z","shell.execute_reply":"2025-02-06T05:16:04.993368Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# splits['train']['slices']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:04.994844Z","iopub.execute_input":"2025-02-06T05:16:04.995055Z","iopub.status.idle":"2025-02-06T05:16:04.998282Z","shell.execute_reply.started":"2025-02-06T05:16:04.995036Z","shell.execute_reply":"2025-02-06T05:16:04.997483Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define the Custom BraTs Dataset","metadata":{}},{"cell_type":"code","source":"class BraTsDataset(Dataset):\n\n    def __init__(self, data_dict, annotations_df, transforms = None, cache_size = 0):\n        self.patient_ids = data_dict['patient_ids']\n        self.slice_paths = data_dict['slices']\n        self.transforms = transforms\n\n        self.cache_size = cache_size\n        self.cache = {}\n        self.labels = dict(zip(annotations_df['BraTS21ID'], annotations_df['MGMT_value'])) \n\n    def __len__(self):\n        return len(self.patient_ids)\n\n    def load_volume(self, patient_id):\n        if patient_id in self.cache:\n            return self.cache[patient_id]\n        slices = []\n        for slice_path in self.slice_paths[patient_id]:\n            dicom_image = pydicom.dcmread(slice_path)\n            image_2d = dicom_image.pixel_array\n            resized_slice = zoom(image_2d, (64/image_2d.shape[0], 64/image_2d.shape[1]))\n            slices.append(resized_slice)\n           \n        volume = np.stack(slices, axis=-1)\n        volume = np.expand_dims(volume, axis=0)\n        volume_tensor = torch.from_numpy(volume).float()\n\n        # Print range before normalization\n        # print(f\"Before normalization: [{volume_tensor.min():.3f}, {volume_tensor.max():.3f}]\")\n\n        # Add normalization here\n        volume_tensor = (volume_tensor - volume_tensor.min()) / (volume_tensor.max() - volume_tensor.min())\n       \n        # Print range after normalization\n        # print(f\"After normalization: [{volume_tensor.min():.3f}, {volume_tensor.max():.3f}]\")\n       \n        \n        if len(self.cache) < self.cache_size:\n            self.cache[patient_id] = volume_tensor\n           \n        return volume_tensor\n\n    \n    def __getitem__(self, idx):\n        \n        patient_id = self.patient_ids[idx]\n        volume = self.load_volume(patient_id)\n        label = torch.tensor(self.labels[patient_id])\n        \n        data = {\"image\": volume, \n                \"patient_id\": patient_id,\n                \"label\": label\n               }\n        \n        # Add print statements for debugging\n        # print(f\"Before transform range: [{data['image'].min():.3f}, {data['image'].max():.3f}]\")\n        # print(\"Data keys:\", data.keys())\n        \n        # if self.transforms:\n        #     data = self.transforms(data)\n            \n        # print(f\"After transform range: [{data['image'].min():.3f}, {data['image'].max():.3f}]\")\n            \n        \n        return data\n        \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:04.999093Z","iopub.execute_input":"2025-02-06T05:16:04.999463Z","iopub.status.idle":"2025-02-06T05:16:05.039878Z","shell.execute_reply.started":"2025-02-06T05:16:04.999425Z","shell.execute_reply":"2025-02-06T05:16:05.039116Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_split = splits['train']\nval_split = splits['val']\ntest_split = splits['test']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:05.040746Z","iopub.execute_input":"2025-02-06T05:16:05.041032Z","iopub.status.idle":"2025-02-06T05:16:05.056983Z","shell.execute_reply.started":"2025-02-06T05:16:05.040998Z","shell.execute_reply":"2025-02-06T05:16:05.056242Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check split data structure\nprint(\"Train split keys:\", train_split.keys())\nprint(\"First few patient IDs:\", train_split['patient_ids'][:3])\n\n# Check if paths are correct\nfirst_patient = train_split['patient_ids'][0]\nprint(\"First patient paths:\", train_split['slices'][first_patient][:3])\n\n# Create dataset and check\ntrain_dataset = BraTsDataset(train_split, annotations_df)\nsample = train_dataset[0]\nprint(f\"Sample shape: {sample['image'].shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:05.057742Z","iopub.execute_input":"2025-02-06T05:16:05.058026Z","iopub.status.idle":"2025-02-06T05:16:05.816251Z","shell.execute_reply.started":"2025-02-06T05:16:05.057994Z","shell.execute_reply":"2025-02-06T05:16:05.815054Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define the Transformations","metadata":{}},{"cell_type":"code","source":"train_transforms = Compose([\nScaleIntensityRanged(\n        keys=[\"image\"],\n        a_min=-76,\n        a_max=3158,\n        b_min=0.0,\n        b_max=1.0,\n        clip=True\n    ),    \n    RandFlipd(keys=[\"image\"], spatial_axis=[0, 1], prob=0.5),\n    RandRotate90d(keys=[\"image\"], prob=0.5, spatial_axes=[0, 1]),\n    RandShiftIntensityd(keys=[\"image\"], prob=0.5, offsets=0.1),\n])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:05.819421Z","iopub.execute_input":"2025-02-06T05:16:05.819656Z","iopub.status.idle":"2025-02-06T05:16:05.826898Z","shell.execute_reply.started":"2025-02-06T05:16:05.819635Z","shell.execute_reply":"2025-02-06T05:16:05.826136Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add print to verify transform is in chain\nprint(\"Transforms:\", train_transforms.transforms)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:05.828294Z","iopub.execute_input":"2025-02-06T05:16:05.828569Z","iopub.status.idle":"2025-02-06T05:16:05.843732Z","shell.execute_reply.started":"2025-02-06T05:16:05.828544Z","shell.execute_reply":"2025-02-06T05:16:05.842966Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_transforms = Compose([\n   ScaleIntensityd(\n       keys=[\"image\"],\n       minv=0.0,\n       maxv=1.0,\n   ),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:05.844577Z","iopub.execute_input":"2025-02-06T05:16:05.844842Z","iopub.status.idle":"2025-02-06T05:16:05.858681Z","shell.execute_reply.started":"2025-02-06T05:16:05.844818Z","shell.execute_reply":"2025-02-06T05:16:05.857889Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create test transforms and loader\ntest_transforms = Compose([\n   ScaleIntensityd(\n       keys=[\"image\"],\n       minv=0.0,\n       maxv=1.0,\n   ),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:05.859502Z","iopub.execute_input":"2025-02-06T05:16:05.859747Z","iopub.status.idle":"2025-02-06T05:16:05.872431Z","shell.execute_reply.started":"2025-02-06T05:16:05.859720Z","shell.execute_reply":"2025-02-06T05:16:05.871600Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = BraTsDataset(train_split, annotations_df, transforms=train_transforms)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:05.873226Z","iopub.execute_input":"2025-02-06T05:16:05.873535Z","iopub.status.idle":"2025-02-06T05:16:05.887234Z","shell.execute_reply.started":"2025-02-06T05:16:05.873515Z","shell.execute_reply":"2025-02-06T05:16:05.886359Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = BraTsDataset(train_split, annotations_df)\nval_dataset = BraTsDataset(val_split, annotations_df)\ntest_dataset = BraTsDataset(test_split, annotations_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:05.888060Z","iopub.execute_input":"2025-02-06T05:16:05.888307Z","iopub.status.idle":"2025-02-06T05:16:05.902078Z","shell.execute_reply.started":"2025-02-06T05:16:05.888287Z","shell.execute_reply":"2025-02-06T05:16:05.901313Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check split data structure\nprint(\"Train split keys:\", train_split.keys())\nprint(\"First few patient IDs:\", train_split['patient_ids'][:3])\n\n# Check if paths are correct\nfirst_patient = train_split['patient_ids'][0]\nprint(\"First patient paths:\", train_split['slices'][first_patient][:3])\n\n# Create dataset and check\ntrain_dataset = BraTsDataset(train_split, annotations_df)\nsample= train_dataset[0]\nprint(f\"Train Sample shape: {sample['image'].shape}\")\nprint()\n\nval_dataset = BraTsDataset(val_split, annotations_df)\nsample= val_dataset[0]\nprint(f\"Validation Sample shape: {sample['image'].shape}\")\nprint()\ntest_dataset = BraTsDataset(val_split, annotations_df)\nsample= test_dataset[0]\nprint(f\"Test Sample shape: {sample['image'].shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:05.902980Z","iopub.execute_input":"2025-02-06T05:16:05.903241Z","iopub.status.idle":"2025-02-06T05:16:09.633359Z","shell.execute_reply.started":"2025-02-06T05:16:05.903217Z","shell.execute_reply":"2025-02-06T05:16:09.632487Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define the DataLoader","metadata":{}},{"cell_type":"code","source":"def custom_collate(batch):\n    \n    min_val = min([item[\"image\"].min().item() for item in batch])\n    max_val = max([item[\"image\"].max().item() for item in batch])\n\n    # print(f\"Collate input range: [{min_val:.3f}, {max_val:.3f}]\")\n    \n    max_depth = max([x[\"image\"].shape[-1] for x in batch])  # x[0] is volume\n    padded_batch = []\n    labels = []\n    for data in batch:\n        volume = data[\"image\"]\n        label = data[\"label\"]\n        pad_size = max_depth - volume.shape[-1]\n        \n        if pad_size > 0:\n            padded_volume = torch.nn.functional.pad(volume, (0, pad_size))\n            padded_batch.append(padded_volume)\n        \n        else:\n            padded_batch.append(volume)\n        labels.append(label)\n    \n    return { \n        \"image\": torch.stack(padded_batch), \n        \"label\": torch.tensor(labels)\n           }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:09.634810Z","iopub.execute_input":"2025-02-06T05:16:09.635029Z","iopub.status.idle":"2025-02-06T05:16:09.640012Z","shell.execute_reply.started":"2025-02-06T05:16:09.635009Z","shell.execute_reply":"2025-02-06T05:16:09.639303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create DataLoader\ntrain_loader = DataLoader(\n   train_dataset,\n   batch_size=4,  # Small batch size for 3D data\n   shuffle=True,\n   num_workers=2,\n   collate_fn=custom_collate,\n   pin_memory=True  # Faster data transfer to GPU\n)\n\n\nval_loader = DataLoader(\n   val_dataset,\n   batch_size=4,  # Small batch size for 3D data\n   shuffle=True,\n   num_workers=2,\n   collate_fn=custom_collate,\n   pin_memory=True  # Faster data transfer to GPU\n)\n\n# Create DataLoader\ntest_loader = DataLoader(\n   test_dataset,\n   batch_size=4,  # Small batch size for 3D data\n   shuffle=False,\n   num_workers=2,\n   collate_fn=custom_collate,\n   pin_memory=True  # Faster data transfer to GPU\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:09.640710Z","iopub.execute_input":"2025-02-06T05:16:09.640922Z","iopub.status.idle":"2025-02-06T05:16:09.687504Z","shell.execute_reply.started":"2025-02-06T05:16:09.640903Z","shell.execute_reply":"2025-02-06T05:16:09.686608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def inspect_batch(dataloader, split_name=\"Unknown\"):\n    \"\"\"Inspects a batch from a given dataloader, printing shape and value range.\"\"\"\n    batch = next(iter(dataloader))  # Get a single batch\n    \n    images, labels = batch[\"image\"], batch[\"label\"]\n    \n    min_val, max_val = images.min().item(), images.max().item()\n    \n    print(f\"\\n--- {split_name} Split Batch Inspection ---\")\n    print(f\"Image Batch Shape: {images.shape}\")  # Expected: (batch_size, channels, height, width, depth)\n    print(f\"Label Batch Shape: {labels.shape}\")  # Should match batch_size\n    print(f\"Value Range: [{min_val:.3f}, {max_val:.3f}]\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:09.688262Z","iopub.execute_input":"2025-02-06T05:16:09.688551Z","iopub.status.idle":"2025-02-06T05:16:09.705382Z","shell.execute_reply.started":"2025-02-06T05:16:09.688530Z","shell.execute_reply":"2025-02-06T05:16:09.704732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# inspect_batch(train_loader, \"Train\")\n# inspect_batch(val_loader, \"Validation\")\n# inspect_batch(test_loader, \"Test\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:09.706007Z","iopub.execute_input":"2025-02-06T05:16:09.706253Z","iopub.status.idle":"2025-02-06T05:16:09.717755Z","shell.execute_reply.started":"2025-02-06T05:16:09.706234Z","shell.execute_reply":"2025-02-06T05:16:09.717223Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Define the model","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:09.718552Z","iopub.execute_input":"2025-02-06T05:16:09.718831Z","iopub.status.idle":"2025-02-06T05:16:09.783154Z","shell.execute_reply.started":"2025-02-06T05:16:09.718803Z","shell.execute_reply":"2025-02-06T05:16:09.782295Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model = DenseNet121(\n#     spatial_dims = 3,\n#     in_channels = 1,\n#     out_channels = 1\n# ).to(device)\n\nmodel = DenseNet169(\n    spatial_dims = 3,\n    in_channels = 1,\n    out_channels = 1\n).to(device)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:09.783999Z","iopub.execute_input":"2025-02-06T05:16:09.784189Z","iopub.status.idle":"2025-02-06T05:16:10.431346Z","shell.execute_reply.started":"2025-02-06T05:16:09.784172Z","shell.execute_reply":"2025-02-06T05:16:10.430695Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = Adam(model.parameters(), lr = 1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:10.431986Z","iopub.execute_input":"2025-02-06T05:16:10.432185Z","iopub.status.idle":"2025-02-06T05:16:10.437807Z","shell.execute_reply.started":"2025-02-06T05:16:10.432167Z","shell.execute_reply":"2025-02-06T05:16:10.436954Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Set up the Training Loop","metadata":{}},{"cell_type":"code","source":"def train_epoch(model, train_loader, val_loader, epochs = 50):\n    best_val_acc = 0.0\n    for epoch in range(epochs):\n        \n        model.train()  # setting the model in train mode\n        train_loss = 0.0 # initialize variable to store the sum of loss\n        \n        for batch in tqdm(train_loader, desc = f'Epoch {epoch+1}/{epochs} - Training'):\n            # Pass through the training set for the no. of epochs\n            images = batch['image'].to(device)\n            labels = batch['label'].float().to(device)\n\n        \n            optimizer.zero_grad()\n            outputs = model(images)\n        \n            loss = criterion(outputs.squeeze(), labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            \n        # Calculatie average loss for epoch\n        avg_train_loss = train_loss/len(train_loader)\n        \n        # Validation Phase\n        model.eval()\n        val_loss = 0.0\n        correct = 0\n        total = 0\n\n        with torch.no_grad(): # No gradient calculation needed\n            for batch in tqdm(val_loader, desc = f'Epoch {epoch + 1}/{epochs} - Validation'):\n                images = batch['image'].to(device)\n                labels = batch['label'].float().to(device)\n                \n                outputs = model(images)\n                \n                val_loss += criterion(outputs.squeeze(), labels).item()\n\n                predicted = (torch.sigmoid(outputs.squeeze()) > 0.5).int()\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n                \n        val_accuracy = 100*correct/total\n        avg_val_loss = val_loss/len(val_loader)\n        \n        if val_accuracy > best_val_acc:\n            best_val_acc = val_accuracy\n            torch.save(model.state_dict(), '/kaggle/working/best_model.pth')\n        \n        # Print epoch results\n        print(f'Epoch [{epoch+1}/{epochs}]')\n        print(f'Training Loss: {avg_train_loss:.4f}')\n        print(f'Validation Loss: {avg_val_loss:.4f}')\n        print(f'Validation Accuracy: {val_accuracy:.2f}%')\n        print('-' * 50)\n\n\n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:10.438499Z","iopub.execute_input":"2025-02-06T05:16:10.438761Z","iopub.status.idle":"2025-02-06T05:16:10.452729Z","shell.execute_reply.started":"2025-02-06T05:16:10.438730Z","shell.execute_reply":"2025-02-06T05:16:10.451923Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run training for 50 epochs\nnum_epochs = 30\ntrain_epoch(model, train_loader, val_loader, epochs=num_epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T05:16:10.453578Z","iopub.execute_input":"2025-02-06T05:16:10.453842Z","iopub.status.idle":"2025-02-06T07:30:42.239839Z","shell.execute_reply.started":"2025-02-06T05:16:10.453810Z","shell.execute_reply":"2025-02-06T07:30:42.238792Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test_model(model, test_loader, criterion):\n    # Load best model weights\n    model.load_state_dict(torch.load('/kaggle/working/best_model.pth'))\n    model.eval()  # Set to evaluation mode\n    \n    test_loss = 0.0\n    correct = 0\n    total = 0\n    \n    # For storing predictions and true labels\n    all_predictions = []\n    all_labels = []\n    \n    test_pbar = tqdm(test_loader, desc='Testing')\n    with torch.no_grad():\n        for batch in test_pbar:\n            images = batch['image'].to(device)\n            labels = batch['label'].to(device)\n            \n            outputs = model(images)\n            test_loss += criterion(outputs.squeeze(), labels.float()).item()\n            \n            predicted = (torch.sigmoid(outputs.squeeze()) > 0.5).int()\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            # Store predictions and labels\n            all_predictions.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            \n            # Update progress bar\n            current_acc = 100 * correct / total\n            test_pbar.set_postfix({'acc': f'{current_acc:.2f}%'})\n    \n    # Calculate final metrics\n    test_accuracy = 100 * correct / total\n    avg_test_loss = test_loss / len(test_loader)\n    \n    print('\\nTest Results:')\n    print(f'Test Loss: {avg_test_loss:.4f}')\n    print(f'Test Accuracy: {test_accuracy:.2f}%')\n    \n    return test_accuracy, avg_test_loss, all_predictions, all_labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T07:30:42.243722Z","iopub.execute_input":"2025-02-06T07:30:42.243962Z","iopub.status.idle":"2025-02-06T07:30:42.251125Z","shell.execute_reply.started":"2025-02-06T07:30:42.243938Z","shell.execute_reply":"2025-02-06T07:30:42.250350Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run testing\ntest_accuracy, test_loss, predictions, true_labels = test_model(model, test_loader, criterion)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T07:30:42.251932Z","iopub.execute_input":"2025-02-06T07:30:42.252206Z","iopub.status.idle":"2025-02-06T07:31:34.011922Z","shell.execute_reply.started":"2025-02-06T07:30:42.252185Z","shell.execute_reply":"2025-02-06T07:31:34.010953Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Test Accuracy: ',test_accuracy)\nprint('Test Loss: ',test_loss)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T07:31:34.012832Z","iopub.execute_input":"2025-02-06T07:31:34.013082Z","iopub.status.idle":"2025-02-06T07:31:34.018185Z","shell.execute_reply.started":"2025-02-06T07:31:34.013050Z","shell.execute_reply":"2025-02-06T07:31:34.017475Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}